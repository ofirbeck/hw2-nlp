{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18785ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import nltk\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from mittens import GloVe\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "533b92fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec_model(sentences, sg, window_size, epochs=150):    \n",
    "    model = Word2Vec(sentences, window=window_size, min_count=1, sg=sg, epochs=epochs, workers=2, seed=42)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d939dec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentences: [['the', 'bank', 'is', 'located', 'near', 'the', 'river', '.'], ['the', 'bank', 'approved', 'my', 'loan', 'application', '.'], ['he', 'rose', 'from', 'his', 'chair', 'to', 'close', 'the', 'window', '.'], ['the', 'rose', 'bloomed', 'beautifully', 'in', 'the', 'garden', '.'], ['the', 'lead', 'actor', 'delivered', 'a', 'stunning', 'performance', '.'], ['exposure', 'to', 'lead', 'is', 'harmful', 'to', 'health', '.'], ['she', 'is', 'reading', 'a', 'book', 'in', 'the', 'library', '.'], ['the', 'book', 'mentioned', 'a', 'fascinating', 'historical', 'event', '.'], ['i', 'need', 'to', 'file', 'a', 'report', 'for', 'my', 'manager', '.'], ['he', 'lost', 'the', 'file', 'containing', 'important', 'documents', '.']]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"The bank is located near the river.\", \n",
    "             \"The bank approved my loan application.\", \n",
    "             \"He rose from his chair to close the window.\", \n",
    "             \"The rose bloomed beautifully in the garden.\", \n",
    "             \"The lead actor delivered a stunning performance.\", \n",
    "             \"Exposure to lead is harmful to health.\", \n",
    "             \"She is reading a book in the library.\",\n",
    "             \"The book mentioned a fascinating historical event.\", \n",
    "             \"I need to file a report for my manager.\", \n",
    "             \"He lost the file containing important documents.\"]\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "print(\"Tokenized sentences:\", tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "71a70d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try both skip-gram and CBOW\n",
    "cbow_model = train_word2vec_model(tokenized_sentences, sg=0, window_size=3)\n",
    "sg_model = train_word2vec_model(tokenized_sentences, sg=1, window_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "166a196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(word, cbow_model, sg_model):\n",
    "    cbow_vector = cbow_model.wv[word]\n",
    "    sg_vector = sg_model.wv[word]\n",
    "    cousine_similarity = cosine_similarity(cbow_vector.reshape(1, -1), sg_vector.reshape(1, -1))\n",
    "    return cousine_similarity[0][0]\n",
    "\n",
    "def get_embeddings_similarity(cbow_model, sg_model):\n",
    "    similarity_per_token = {}\n",
    "    for sentence in tokenized_sentences:\n",
    "        for token in sentence:\n",
    "            similarity = calculate_similarity(token, cbow_model, sg_model)\n",
    "            similarity_per_token[token] = similarity\n",
    "    return similarity_per_token\n",
    "\n",
    "def get_most_similar_embeddings(cbow_model, sg_model):\n",
    "    similarity_per_token = get_embeddings_similarity(cbow_model, sg_model)\n",
    "    most_similar_embeddings = sorted(similarity_per_token.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    print(\"The most similar embeddings between CBOW and Skip-gram models are: \", most_similar_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a21e2fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 0.96450263, 'bank': 0.90237683, 'is': 0.89742625, 'located': 0.9291422, 'near': 0.9399378, 'river': 0.8926098, '.': 0.9640477, 'approved': 0.96861017, 'my': 0.88274944, 'loan': 0.92010915, 'application': 0.9270045, 'he': 0.8928302, 'rose': 0.9424402, 'from': 0.8979327, 'his': 0.9245022, 'chair': 0.9166998, 'to': 0.9632003, 'close': 0.94737667, 'window': 0.9492069, 'bloomed': 0.9562955, 'beautifully': 0.9413059, 'in': 0.8872272, 'garden': 0.93698025, 'lead': 0.92818147, 'actor': 0.8966482, 'delivered': 0.8933069, 'a': 0.9393356, 'stunning': 0.89599556, 'performance': 0.91019404, 'exposure': 0.95134217, 'harmful': 0.92996186, 'health': 0.8638738, 'she': 0.93199897, 'reading': 0.95338136, 'book': 0.91429466, 'library': 0.94898564, 'mentioned': 0.919379, 'fascinating': 0.9435926, 'historical': 0.9287566, 'event': 0.9360674, 'i': 0.9141132, 'need': 0.87402284, 'file': 0.9229257, 'report': 0.9319524, 'for': 0.9113668, 'manager': 0.8415194, 'lost': 0.9315098, 'containing': 0.90864754, 'important': 0.8391463, 'documents': 0.90661556}\n"
     ]
    }
   ],
   "source": [
    "# the difference between the models on each token\n",
    "print(get_embeddings_similarity(cbow_model, sg_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c188eef3",
   "metadata": {},
   "source": [
    "### The main difference between CBOW and Skip-gram is that CBOW predicts the target word from the context words, while Skip-gram predicts the context words from the target word.\n",
    "### Because the amount of sentences we have trained on isn't big, we see that most of the words have similar Vecs between the models, using cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdee50d",
   "metadata": {},
   "source": [
    "## The most similar embeddings between the models are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e093192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar embeddings between CBOW and Skip-gram models are:  [('approved', 0.96861017), ('the', 0.96450263), ('.', 0.9640477), ('to', 0.9632003), ('bloomed', 0.9562955), ('reading', 0.95338136), ('exposure', 0.95134217), ('window', 0.9492069), ('library', 0.94898564), ('close', 0.94737667)]\n"
     ]
    }
   ],
   "source": [
    "get_most_similar_embeddings(cbow_model, sg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "57b9a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check similarity between the models in certain window size\n",
    "def check_similarity_in_window_size(window):\n",
    "    cbow_model_window = train_word2vec_model(tokenized_sentences, sg=0, window_size=window)\n",
    "    sg_model_window = train_word2vec_model(tokenized_sentences, sg=1, window_size=window)\n",
    "    print(f\"Word embeddings with window size {window}:\")\n",
    "    print(get_embeddings_similarity(cbow_model_window, sg_model_window))\n",
    "    # print(f\"Most similar embeddings with window size {window}:\")\n",
    "    # get_most_similar_embeddings(cbow_model_window, sg_model_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "74f9511f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings with window size 3:\n",
      "{'the': 0.96450263, 'bank': 0.90237683, 'is': 0.89742625, 'located': 0.9291422, 'near': 0.9399378, 'river': 0.8926098, '.': 0.9640477, 'approved': 0.96861017, 'my': 0.88274944, 'loan': 0.92010915, 'application': 0.9270045, 'he': 0.8928302, 'rose': 0.9424402, 'from': 0.8979327, 'his': 0.9245022, 'chair': 0.9166998, 'to': 0.9632003, 'close': 0.94737667, 'window': 0.9492069, 'bloomed': 0.9562955, 'beautifully': 0.9413059, 'in': 0.8872272, 'garden': 0.93698025, 'lead': 0.92818147, 'actor': 0.8966482, 'delivered': 0.8933069, 'a': 0.9393356, 'stunning': 0.89599556, 'performance': 0.91019404, 'exposure': 0.95134217, 'harmful': 0.92996186, 'health': 0.8638738, 'she': 0.93199897, 'reading': 0.95338136, 'book': 0.91429466, 'library': 0.94898564, 'mentioned': 0.919379, 'fascinating': 0.9435926, 'historical': 0.9287566, 'event': 0.9360674, 'i': 0.9141132, 'need': 0.87402284, 'file': 0.9229257, 'report': 0.9319524, 'for': 0.9113668, 'manager': 0.8415194, 'lost': 0.9315098, 'containing': 0.90864754, 'important': 0.8391463, 'documents': 0.90661556}\n",
      "Word embeddings with window size 5:\n",
      "{'the': 0.974435, 'bank': 0.82309985, 'is': 0.8752453, 'located': 0.89234465, 'near': 0.92561007, 'river': 0.91139483, '.': 0.9541203, 'approved': 0.90014505, 'my': 0.89507604, 'loan': 0.83819324, 'application': 0.87543654, 'he': 0.88370466, 'rose': 0.92342925, 'from': 0.8919568, 'his': 0.9155226, 'chair': 0.9018526, 'to': 0.9289352, 'close': 0.91478425, 'window': 0.9153966, 'bloomed': 0.9321029, 'beautifully': 0.9264147, 'in': 0.91124713, 'garden': 0.9203027, 'lead': 0.897081, 'actor': 0.92610276, 'delivered': 0.8858505, 'a': 0.94902104, 'stunning': 0.8663567, 'performance': 0.9099649, 'exposure': 0.91062504, 'harmful': 0.9122064, 'health': 0.92363274, 'she': 0.9288174, 'reading': 0.9277069, 'book': 0.8953163, 'library': 0.93895847, 'mentioned': 0.9151179, 'fascinating': 0.91752344, 'historical': 0.9195354, 'event': 0.91611844, 'i': 0.9322753, 'need': 0.87944674, 'file': 0.91599184, 'report': 0.8902229, 'for': 0.92728907, 'manager': 0.8686979, 'lost': 0.8947515, 'containing': 0.8861097, 'important': 0.8338021, 'documents': 0.87910527}\n",
      "Word embeddings with window size 7:\n",
      "{'the': 0.9572747, 'bank': 0.77315015, 'is': 0.8409888, 'located': 0.8240395, 'near': 0.84853745, 'river': 0.8193824, '.': 0.96172446, 'approved': 0.8564518, 'my': 0.8167487, 'loan': 0.7866394, 'application': 0.8403408, 'he': 0.8750089, 'rose': 0.89946854, 'from': 0.84234333, 'his': 0.9150871, 'chair': 0.8737297, 'to': 0.93812793, 'close': 0.91660416, 'window': 0.9127553, 'bloomed': 0.80131924, 'beautifully': 0.87989247, 'in': 0.87146807, 'garden': 0.7993636, 'lead': 0.8755293, 'actor': 0.8501969, 'delivered': 0.81538475, 'a': 0.9347633, 'stunning': 0.81838125, 'performance': 0.8831423, 'exposure': 0.83864385, 'harmful': 0.84344274, 'health': 0.8020685, 'she': 0.8864297, 'reading': 0.9098532, 'book': 0.86008644, 'library': 0.8990086, 'mentioned': 0.85226315, 'fascinating': 0.86430764, 'historical': 0.87640685, 'event': 0.87939644, 'i': 0.8921782, 'need': 0.8293532, 'file': 0.91715264, 'report': 0.8826117, 'for': 0.8932689, 'manager': 0.8575734, 'lost': 0.81780314, 'containing': 0.8763434, 'important': 0.8246604, 'documents': 0.7889028}\n",
      "Word embeddings with window size 9:\n",
      "{'the': 0.9536199, 'bank': 0.7885674, 'is': 0.77734005, 'located': 0.7901905, 'near': 0.8321878, 'river': 0.7441212, '.': 0.957414, 'approved': 0.86661625, 'my': 0.8141663, 'loan': 0.79942214, 'application': 0.82534295, 'he': 0.89550567, 'rose': 0.8718383, 'from': 0.7844474, 'his': 0.9103656, 'chair': 0.8719282, 'to': 0.94336796, 'close': 0.9062176, 'window': 0.8663013, 'bloomed': 0.8867647, 'beautifully': 0.90373236, 'in': 0.8250432, 'garden': 0.83597934, 'lead': 0.86266583, 'actor': 0.8222144, 'delivered': 0.8217923, 'a': 0.9332877, 'stunning': 0.80759203, 'performance': 0.85282177, 'exposure': 0.83447695, 'harmful': 0.8478742, 'health': 0.7301881, 'she': 0.8405306, 'reading': 0.84577805, 'book': 0.8269331, 'library': 0.89448017, 'mentioned': 0.8014085, 'fascinating': 0.860202, 'historical': 0.83519375, 'event': 0.8583971, 'i': 0.92739266, 'need': 0.8511199, 'file': 0.9433151, 'report': 0.88001776, 'for': 0.87802815, 'manager': 0.816892, 'lost': 0.8544501, 'containing': 0.85388297, 'important': 0.8582163, 'documents': 0.8339119}\n"
     ]
    }
   ],
   "source": [
    "# original window size\n",
    "check_similarity_in_window_size(3)\n",
    "# with window size 5\n",
    "check_similarity_in_window_size(5)\n",
    "# with window size 7\n",
    "check_similarity_in_window_size(7)\n",
    "# with window size 9\n",
    "check_similarity_in_window_size(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3280fdef",
   "metadata": {},
   "source": [
    "### We can see that the cosine similarity of the words is significantly increasing between the models when increasing the window size - because it strengths the unique functionality of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8bc21d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between words with similar syntax with CBOW:\n",
      "Similarity between 'he' and 'she': 0.22245267033576965\n",
      "Similarity between 'stunning' and 'fascinating': 0.11417089402675629\n",
      "Similarity between 'book' and 'report': 0.4146587550640106\n",
      "Similarity between words with similar syntax with Skip-gram:\n",
      "Similarity between 'he' and 'she': 0.6084062457084656\n",
      "Similarity between 'stunning' and 'fascinating': 0.4872681796550751\n",
      "Similarity between 'book' and 'report': 0.7794286608695984\n",
      "Similarity between words with similar semantics with CBOW:\n",
      "Similarity between 'rose' and 'garden': 0.16565127670764923\n",
      "Similarity between 'file' and 'report': 0.5214782357215881\n",
      "Similarity between 'bank' and 'loan': 0.18064366281032562\n",
      "Similarity between words with similar semantics with Skip-gram:\n",
      "Similarity between 'rose' and 'garden': 0.5085529088973999\n",
      "Similarity between 'file' and 'report': 0.8609709143638611\n",
      "Similarity between 'bank' and 'loan': 0.5230200886726379\n"
     ]
    }
   ],
   "source": [
    "def get_words_simlarity(model, words_dict):\n",
    "    for word1, word2 in words_dict.items():\n",
    "        similarity = model.wv.similarity(word1, word2)\n",
    "        print(f\"Similarity between '{word1}' and '{word2}': {similarity}\")\n",
    "\n",
    "\n",
    "# check similarity between two words with similar syntax\n",
    "same_syntax_words = {\n",
    "    \"he\": \"she\",\n",
    "    \"stunning\": \"fascinating\",\n",
    "    \"book\": \"report\"\n",
    "}\n",
    "print(\"Similarity between words with similar syntax with CBOW:\")\n",
    "get_words_simlarity(cbow_model, same_syntax_words)\n",
    "print(\"Similarity between words with similar syntax with Skip-gram:\")\n",
    "get_words_simlarity(sg_model, same_syntax_words)\n",
    "\n",
    "# check similarity between two words with similar semantics\n",
    "similar_semantics_words = {\n",
    "    \"rose\" : \"garden\",\n",
    "    \"file\": \"report\",\n",
    "    \"bank\": \"loan\"\n",
    "}\n",
    "\n",
    "print(\"Similarity between words with similar semantics with CBOW:\")\n",
    "get_words_simlarity(cbow_model, similar_semantics_words)\n",
    "print(\"Similarity between words with similar semantics with Skip-gram:\")\n",
    "get_words_simlarity(sg_model, similar_semantics_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b148e62",
   "metadata": {},
   "source": [
    "## We can see that Skip-Grem outperformed CBOW in recognizing both semantic and syntax relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "704bfdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the word: bank the similarity between CBOW and Skip-gram models is:\n",
      "0.90237683\n",
      "For the word: rose the similarity between CBOW and Skip-gram models is:\n",
      "0.9424402\n",
      "For the word: lead the similarity between CBOW and Skip-gram models is:\n",
      "0.92818147\n",
      "For the word: book the similarity between CBOW and Skip-gram models is:\n",
      "0.91429466\n",
      "For the word: file the similarity between CBOW and Skip-gram models is:\n",
      "0.9229257\n"
     ]
    }
   ],
   "source": [
    "# compare the models for the words bank, rose, lead, book and file\n",
    "words_to_compare = ['bank', 'rose', 'lead', 'book', 'file']\n",
    "for word in words_to_compare:\n",
    "    print(\"For the word:\", word, \"the similarity between CBOW and Skip-gram models is:\")\n",
    "    print(calculate_similarity(word, cbow_model, sg_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ee1d4f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with fasttext:\n",
      "Similarity between 'bank' and 'banking': 0.39471450448036194\n",
      "Similarity between 'rose' and 'roses': 0.4105513393878937\n",
      "Similarity between 'lead' and 'leading': 0.21785584092140198\n",
      "Similarity between 'book' and 'books': 0.4938759207725525\n",
      "Similarity between 'file' and 'files': 0.5773593187332153\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = FastText(sentences=tokenized_sentences, window=3, sg=1)\n",
    "print(\"Similarities with fasttext:\")\n",
    "\n",
    "fasttext_pairs = {\n",
    "    \"bank\": \"banking\",\n",
    "    \"rose\": \"roses\",\n",
    "    \"lead\": \"leading\",\n",
    "    \"book\": \"books\",\n",
    "    \"file\": \"files\"\n",
    "}\n",
    "for word1, word2 in fasttext_pairs.items():\n",
    "    similarity = fasttext_model.wv.similarity(word1, word2)\n",
    "    print(f\"Similarity between '{word1}' and '{word2}': {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df5f63",
   "metadata": {},
   "source": [
    "## 2. Contextual embeddings take into account words with multiple meanings (polysemy), by saving a vector for each of the appearances of that word, resulting in a better understanding of each meaning, not like in static models like Word2Vec which only saves one vector for each word.\n",
    "\n",
    "### These 2 examples show the polysemy \"bank\" with its different meanings\n",
    "### 1. The bank approved my loan application.\n",
    "### 2. The bank is located the river.\n",
    "\n",
    "### Contextual embedding would create 2 separate vectors for each of the different meanings of bank, and static embedding would have one for both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc0280",
   "metadata": {},
   "source": [
    "## 3. Sharon stated we shouldn't do this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57509ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brown sentences: [['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]\n",
      "Similarity between words with similar semantics in brown:\n",
      "Similarity between 'king' and 'queen': 0.9420989155769348\n",
      "Similarity between 'man' and 'woman': 0.895228385925293\n",
      "Similarity between 'apple' and 'orange': 0.9580438137054443\n"
     ]
    }
   ],
   "source": [
    "# use the brown corpus to train word2vec\n",
    "brown_sentences = nltk.corpus.brown.sents()\n",
    "print(\"Brown sentences:\", brown_sentences)\n",
    "brown_model = train_word2vec_model(brown_sentences, sg=1, window_size=3, epochs=5)\n",
    "words_to_compare_brown = {\"king\": \"queen\", \"man\": \"woman\", \"apple\": \"orange\"}\n",
    "\n",
    "print(\"Similarity between words with similar semantics in brown:\")\n",
    "get_words_simlarity(brown_model, words_to_compare_brown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42b239",
   "metadata": {},
   "source": [
    "## 4.b Because these pairs have similar semantic meanings the cosine similarity between them are strong, as man and woman are both genders, king and queen are rules, and apple and orange are fruits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3420b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
